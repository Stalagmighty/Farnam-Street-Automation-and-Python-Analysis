import re
import pandas as pd
from collections import Counter
from googleapiclient.discovery import build
from google.oauth2 import service_account
import matplotlib.pyplot as plt
from openai import OpenAI

# Path to your service account key file
SERVICE_ACCOUNT_FILE = r'C:\Users\USER\OneDrive\Coding Projects\FS Analysis and Automation\Credentials\python-fs-automation.json' #Replace with .json Google Service Account file path

# Define the required scope
SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']

# Authenticate with the service account
credentials = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES)

# The ID of your Google Sheet
SPREADSHEET_ID = 'SPREADSHEET ID'  # Replace with your Google Sheet ID (long string of numbers in the middle of the Google Sheet URL)
RANGE_NAME = 'FS_Main_Text!A1:B200'  # Replace with the range of data you want to read

# Build the Sheets API service
service = build('sheets', 'v4', credentials=credentials)
sheet = service.spreadsheets()

# Read the data from the sheet
result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()
values = result.get('values', [])

# Function to clean and format a cell's content
def clean_text(cell):
    if not isinstance(cell, str):
        return cell
    # Remove excessive whitespace, line breaks, and escape sequences
    cleaned = re.sub(r'[\r\n\t]+', ' ', cell)  # Replace line breaks and tabs with a space
    cleaned = re.sub(r'\u2007|\xad|[\u2000-\u200F]', '', cleaned)  # Remove specific Unicode artifacts
    cleaned = re.sub(r'\s{2,}', ' ', cleaned)  # Collapse multiple spaces into one
    cleaned = re.sub(r'[^\S\r\n]{2,}', ' ', cleaned)  # Remove repetitive invisible sequences
    return cleaned.strip()

# Clean the data and convert it to a DataFrame
if not values:
    print('No data found.')
else:
    cleaned_data = [[clean_text(cell) for cell in row] for row in values]
    df = pd.DataFrame(cleaned_data, columns=['Date', 'Content'])  # Adjust column names as needed
    print(df)

    # Word Count Analysis
    # Combine all content into a single string for analysis
    all_content = ' '.join(df['Content'].dropna())

    # Normalize the text to lowercase and split it into words
    # Use regex to extract sequences of alphanumeric characters (words)
    words = re.findall(r'\b\w+\b', all_content.lower())

    # Count the frequency of each word using the Counter class from collections
    # Counter creates a dictionary where keys are words and values are their counts
    word_counts = Counter(words)

    # List of common words to exclude (stop words) as well as specific words that appeared in the emails that were reptitive but not useful.
    stop_words = {
        'the', 'to', 'you', 'and', 'a', 'of', 'is', 'it', 'on', 'that', 'in', 's', 'your', 've', 'am',
        'can', 'shouldn', 'down', 'from', "wouldn’t", 'as', 'be', 'are', 'too', 'through', "don’t",
        'does', 'a', 'but', 'now', 'some', 'an', "couldn’t", 'we', 'below', 'against', 'here', 'won',
        'did', 'yourselves', 'was', 'how', 'above', 'him', 'shan', 'it', 'which', "weren’t", 'himself',
        'its', 'most', 'the', 'wouldn', 'needn', 're', 'or', 'while', "mustn’t", 'your', 'if', "hasn’t",
        "shouldn’t", 'yours', 'she', 'her', 'wasn', 'other', 'aren', 'any', 'll', 'off', 'couldn',
        'ain', "wasn’t", 'few', 'is', 'of', 'there', "isn’t", 'than', "shan’t", 'why', 'has', 'so', 'in',
        "didn’t", 'only', 'have', 'itself', 'for', 'under', 'own', 'hasn', 'were', "doesn’t", "needn’t",
        'those', 'isn', 'out', 'very', "won’t", 'until', 'hers', 'after', "it’s", 'up', 'they', 'their',
        'not', 'doing', 'no', 'them', 'where', 'ourselves', 'themselves', "aren’t", 'our', 'on', 'that',
        'theirs', 'nor', 't', 'ours', 'at', 's', 'again', 'same', 'over', 'just', 'ma', 'because', 'who',
        'mightn', "you’ve", 'before', 'by', 'more', "should’ve", 'being', 'had', 'weren', 'this',
        "mightn’t", 'm', 'with', 'should', "haven’t", "hadn’t", 'what', "that’ll", "you’re", 'during',
        'haven', 'herself', 'and', 'these', 'such', 'further', 'mustn', 'do', "you’d", 'having', 'didn',
        'd', 'hadn', 'y', 'yourself', 'his', 'into', 'once', 'each', 'don', 'all', 'then', 'both', 'when',
        'he', 'will', 'me', 'whom', 'i', 'my', 'you', 'to', 'between', 'myself', 'doesn', 'about', 'been',
        'o', "you’ll", "she’s", 'fs', 'one', 'p', 'subscribe','unsubscribe', '30', 'get', 'like','email', 'free',
        'brain', 'food', 'access', 'everything'
    }

    # Filter out the stop words from the word counts
    filtered_word_counts = {word: count for word, count in word_counts.items() if word not in stop_words}

    # Convert the filtered word counts into a Pandas DataFrame for easier analysis
    word_counts_df = pd.DataFrame(filtered_word_counts.items(), columns=['Word', 'Count'])

    # Sort the DataFrame by the 'Count' column in descending order to see the most common words
    word_counts_df = word_counts_df.sort_values(by='Count', ascending=False)

    # Display the top 20 most common words
    print("Top 20 most common words (excluding stop words):")
    print(word_counts_df.head(20))

    # Plotting the top 20 words
    top_words = word_counts_df.head(20)  # Get the top 20 most common words
    plt.figure(figsize=(10, 6))  # Set the figure size

    # Create a bar chart
    plt.bar(top_words['Word'], top_words['Count'], alpha=0.75)
    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
    plt.xlabel('Words')
    plt.ylabel('Frequency')
    plt.title('Top 20 Most Common Words (Excluding Stop Words)')
    plt.tight_layout()  # Adjust layout to avoid clipping of labels

    # Show the chart
    plt.show()

    ## CHAT GPT SECTION

    # Set up OpenAI API key
    client = OpenAI(api_key="sk-") # Insert your OpenAI key that begins with sk

    # Generate a prompt for ChatGPT based on the top 20 words
    top_20_words = word_counts_df.head(20)
    words_list = ', '.join(top_20_words['Word'].tolist())

    # Prompt for ChatGPT
    prompt = f"The top 20 most common words in my dataset are: {words_list}. Provide a summary or insights about what these words might indicate."

    # Call OpenAI API with the updated ChatCompletion method
    response = client.chat.completions.create(model="gpt-4o-mini",  # Replace with your preferred model
    messages=[
        {"role": "system", "content": "You are a helpful assistant who analyzes data."},
        {"role": "user", "content": prompt}
    ],
    max_tokens=150,
    temperature=0.7)

    # Extract and print the AI-generated insights
    print("ChatGPT Analysis:")
    print(response.choices[0].message.content.strip())


